{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd66b7a",
   "metadata": {},
   "source": [
    "## Job segmentation by deep learning\n",
    "\n",
    "In this notebook, I show how to use deep learning to classify the sentences from job descriptions into different catalogues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fce34b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, \n",
    "    Bidirectional, \n",
    "    Dense, \n",
    "    LSTM, \n",
    "    GlobalAveragePooling1D, \n",
    "    Conv1D, \n",
    "    GlobalMaxPooling1D, \n",
    "    MultiHeadAttention, \n",
    "    LayerNormalization,\n",
    "    Dropout,   \n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e0e9e",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "Just some samples in DATADIR, due to data protection reason, cannot release the full dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e546254",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "DATADIR = \"./data/\"\n",
    "\n",
    "VOCAB_SIZE = 10000  # Total vocabulary size\n",
    "MAX_LEN = 100  # Maximum lenght of a sentence\n",
    "EMBED_SIZE = 32  # Embedding size for each token\n",
    "\n",
    "NUM_HEADS = 2  # Number of attention heads\n",
    "FF_SIZE = 32  # Hidden layer size in feed forward network inside transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f715c4d",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a28632bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23975 files belonging to 4 classes.\n",
      "Using 19180 files for training.\n",
      "Found 23975 files belonging to 4 classes.\n",
      "Using 4795 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = preprocessing.text_dataset_from_directory(\n",
    "    DATADIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=SEED)\n",
    "\n",
    "valid_ds = preprocessing.text_dataset_from_directory(\n",
    "    DATADIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05833abe",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c8546bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_LEN\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(train_ds.map(lambda x, y: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "877a3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    input_dim=VOCAB_SIZE,\n",
    "    output_dim=EMBED_SIZE,\n",
    "    mask_zero=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c73a4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_lstm = [\n",
    "    vectorize_layer,\n",
    "    embedding_layer,\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation=\"softmax\")\n",
    "]\n",
    "\n",
    "lstm_model = Sequential(layers_lstm)\n",
    "\n",
    "lstm_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c45d821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 74s 115ms/step - loss: 1.2294 - accuracy: 0.5104 - val_loss: 0.9269 - val_accuracy: 0.6646\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 65s 108ms/step - loss: 0.7751 - accuracy: 0.7444 - val_loss: 0.6931 - val_accuracy: 0.7948\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 65s 109ms/step - loss: 0.6031 - accuracy: 0.8214 - val_loss: 0.6095 - val_accuracy: 0.8167\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 72s 121ms/step - loss: 0.5050 - accuracy: 0.8538 - val_loss: 0.5591 - val_accuracy: 0.8385\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 67s 111ms/step - loss: 0.4393 - accuracy: 0.8770 - val_loss: 0.5265 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f568dd35880>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(\n",
    "    x=train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=30,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b7f2df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\"knowledge of python, R\", \"Fluent english\"]\n",
    "\n",
    "probs = lstm_model.predict(samples)\n",
    "labels = np.argmax(probs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "225edc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f81bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1c4cd8",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f88d53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_cnn = [\n",
    "    vectorize_layer,\n",
    "    embedding_layer,\n",
    "    Conv1D(64, 5, activation=\"relu\", strides=2),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation=\"softmax\")\n",
    "]\n",
    "\n",
    "cnn_model = Sequential(layers_cnn)\n",
    "\n",
    "cnn_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75eff55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 15s 24ms/step - loss: 1.1717 - accuracy: 0.5588 - val_loss: 0.8858 - val_accuracy: 0.7031\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.6828 - accuracy: 0.7934 - val_loss: 0.5821 - val_accuracy: 0.8198\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.4825 - accuracy: 0.8529 - val_loss: 0.5366 - val_accuracy: 0.8219\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 15s 24ms/step - loss: 0.4080 - accuracy: 0.8740 - val_loss: 0.5030 - val_accuracy: 0.8406\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.3638 - accuracy: 0.8888 - val_loss: 0.4817 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56bbb50f40>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(\n",
    "    x=train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=30,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f49fb0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56bb233160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "samples = [\"knowledge of python, R\", \"Fluent english\"]\n",
    "\n",
    "probs = cnn_model.predict(samples)\n",
    "labels = np.argmax(probs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f15cfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5e5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b2d9cc",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6cb5e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5afad272",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBED_SIZE)\n",
    "transformer_block = TransformerBlock(EMBED_SIZE, NUM_HEADS, FF_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ac1601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_transformer = [\n",
    "    vectorize_layer,\n",
    "    embedding_layer,\n",
    "    transformer_block,\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation=\"softmax\")\n",
    "]\n",
    "\n",
    "transformer_model = Sequential(layers_transformer)\n",
    "\n",
    "transformer_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b226793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 26s 41ms/step - loss: 1.3221 - accuracy: 0.3888 - val_loss: 1.2359 - val_accuracy: 0.4260\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 1.0600 - accuracy: 0.5659 - val_loss: 0.9212 - val_accuracy: 0.6156\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.7320 - accuracy: 0.7529 - val_loss: 0.6393 - val_accuracy: 0.8010\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.5054 - accuracy: 0.8358 - val_loss: 0.5134 - val_accuracy: 0.8406\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.3901 - accuracy: 0.8736 - val_loss: 0.4428 - val_accuracy: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56bba983d0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model.fit(\n",
    "    x=train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=30,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e680d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
