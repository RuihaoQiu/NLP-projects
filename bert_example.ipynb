{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-example.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPRAHmeQMopqxsi2yWA+fWd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuihaoQiu/NLP-projects/blob/master/bert_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5rXQSdpnn_L",
        "colab_type": "text"
      },
      "source": [
        "## An example of BERT\n",
        "ref \n",
        "1. https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
        "2. https://www.kdnuggets.com/2020/02/intent-recognition-bert-keras-tensorflow.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0jw2JOPn3aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## use bert for tensorflow 2\n",
        "!pip install bert-for-tf2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m2IJ1sbmT41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlTpJI_-n7Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QyMu8mpu4r8",
        "colab_type": "text"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDO2Uk6_oMLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE-nxV1ntaYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = download_and_load_datasets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tD-0KIctdTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.sample(5000)\n",
        "test = test.sample(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSUUH4ZUti-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na5evz7tu-fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zQF0Mhx6x7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"train_set.csv\")\n",
        "test = pd.read_csv(\"test_set.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUvCgQrzfa93",
        "colab_type": "text"
      },
      "source": [
        "### Load bert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLZn4DLAu-oT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnKiNB9LfgCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_folder = \"uncased_L-12_H-768_A-12/\"\n",
        "bert_config_file = os.path.join(bert_folder, \"bert_config.json\")\n",
        "bert_ckpt_file = os.path.join(bert_folder, \"bert_model.ckpt\")\n",
        "bert_vocab_file = os.path.join(bert_folder, \"vocab.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_hevia1vA8c",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-FvJxZMf5Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = FullTokenizer(vocab_file=bert_vocab_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM3BK4U7zFoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wswibNNt3Rx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")\n",
        "tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anb5XlWZ-Apg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1CGvH5JJASh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {\n",
        "    \"company\" : 0,\n",
        "    \"tasks\": 1,\n",
        "    \"profile\": 2,\n",
        "    \"benefits\": 3\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH4uZJ_v5NUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _convert_single(input_text):\n",
        "  tokens = tokenizer.tokenize(input_text)\n",
        "  tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  return token_ids\n",
        "\n",
        "def _convert_multiple(input_list):\n",
        "  token_ids_list = []\n",
        "  max_len = 1\n",
        "  for sent in tqdm(input_list):\n",
        "    token_ids = _convert_single(sent)\n",
        "    token_ids_list.append(token_ids)\n",
        "  return token_ids_list\n",
        "\n",
        "def _pad(token_ids_list):\n",
        "  x_padded = []\n",
        "  for input_ids in token_ids_list:\n",
        "    input_ids = input_ids[:min(len(input_ids), max_len - 2)]\n",
        "    input_ids = input_ids + [0] * (max_len - len(input_ids))\n",
        "    x_padded.append(np.array(input_ids))\n",
        "  return np.array(x_padded)\n",
        "\n",
        "def convert(input_list):\n",
        "  token_ids_list = _convert_multiple(input_list)\n",
        "  out_array = _pad(token_ids_list)\n",
        "  return out_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYHEye2I6xyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = convert(train.sentence)\n",
        "X_test = convert(test.sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uska8UwHARVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = train.label.map(label_dict).values\n",
        "y_test = test.label.map(label_dict).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_D1y9aXJdJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = np.array([0,1,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNDOC8bRF5Eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRGa0uulC1nc",
        "colab_type": "text"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oljAqxKPHGzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGC4xDsvC0PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "\n",
        "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
        "      bc = StockBertConfig.from_json_string(reader.read())\n",
        "      bert_params = map_stock_config_to_params(bc)\n",
        "      bert_params.adapter_size = None\n",
        "      bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
        "\n",
        "  input_ids = tf.keras.layers.Input(\n",
        "    shape=(max_len, ),\n",
        "    dtype='int32',\n",
        "    name=\"input_ids\"\n",
        "  )\n",
        "  bert_output = bert(input_ids)\n",
        "\n",
        "  print(\"bert shape\", bert_output.shape)\n",
        "\n",
        "  cls_out = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
        "  cls_out = tf.keras.layers.Dropout(0.5)(cls_out)\n",
        "  logits = tf.keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
        "  logits = tf.keras.layers.Dropout(0.5)(logits)\n",
        "  logits = tf.keras.layers.Dense(\n",
        "    units=len(classes),\n",
        "    activation=\"softmax\"\n",
        "  )(logits)\n",
        "\n",
        "  model = tf.keras.Model(inputs=input_ids, outputs=logits)\n",
        "  model.build(input_shape=(None, max_len))\n",
        "\n",
        "  load_stock_weights(bert, bert_ckpt_file)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPo-Z2LC3v66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dATelH3G3nZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kf-aZlvSPBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeY3xhE4TMJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = \"log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%s\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "history = model.fit(\n",
        "  x=X_train, \n",
        "  y=y_train,\n",
        "  validation_split=0.2,\n",
        "  batch_size=32,\n",
        "  shuffle=True,\n",
        "  epochs=10,\n",
        "  callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}